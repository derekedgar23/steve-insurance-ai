import streamlit as st
import pandas as pd
import numpy as np
import PyPDF2
import pdfplumber
import plotly.express as px
import plotly.graph_objects as go
import re
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

st.set_page_config(
    page_title="STEVE - Insurance AI",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f4e79;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .chat-container {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .steve-response {
        background-color: #e3f2fd;
        border-left: 4px solid #2196f3;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .user-message {
        background-color: #f1f8e9;
        border-left: 4px solid #4caf50;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

class SteveWebApp:
    def __init__(self):
        self.insurance_keywords = {
            'claims': ['claim', 'loss', 'incident', 'accident', 'damage', 'injury', 'liability'],
            'policy': ['policy', 'premium', 'coverage', 'deductible', 'limit', 'insured'],
            'financial': ['reserve', 'paid', 'outstanding', 'incurred', 'expense', 'settlement'],
            'legal': ['litigation', 'suit', 'attorney', 'court', 'judgment'],
            'regulatory': ['filing', 'compliance', 'audit', 'examination']
        }
        
        if 'analyzed_data' not in st.session_state:
            st.session_state.analyzed_data = {}
        if 'chat_history' not in st.session_state:
            st.session_state.chat_history = []
    
    def analyze_csv(self, uploaded_file):
        try:
            df = pd.read_csv(uploaded_file)
            filename = uploaded_file.name
            
            analysis = {
                'filename': filename,
                'type': 'CSV',
                'rows': len(df),
                'columns': len(df.columns),
                'column_names': list(df.columns),
                'dataframe': df,
                'insurance_columns': [],
                'data_quality': {},
                'recommendations': [],
                'summary_stats': {}
            }
            
            for col in df.columns:
                col_lower = col.lower()
                for category, keywords in self.insurance_keywords.items():
                    if any(keyword in col_lower for keyword in keywords):
                        analysis['insurance_columns'].append({
                            'column': col,
                            'category': category
                        })
            
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            for col in numeric_cols:
                if not df[col].empty and not df[col].isna().all():
                    analysis['summary_stats'][col] = {
                        'mean': float(df[col].mean()),
                        'median': float(df[col].median()),
                        'min': float(df[col].min()),
                        'max': float(df[col].max()),
                        'sum': float(df[col].sum()),
                        'std': float(df[col].std())
                    }
            
            missing_data = {}
            for col in df.columns:
                null_pct = (df[col].isnull().sum() / len(df)) * 100
                if null_pct > 5:
                    missing_data[col] = {
                        'count': int(df[col].isnull().sum()),
                        'percentage': round(null_pct, 1)
                    }
            
            analysis['data_quality']['missing_data'] = missing_data
            analysis['data_quality']['duplicates'] = len(df) - len(df.drop_duplicates())
            
            if analysis['insurance_columns']:
                analysis['recommendations'].append("ğŸ“Š Insurance data detected - ready for analysis!")
            if missing_data:
                analysis['recommendations'].append("âš ï¸ Some columns have missing data - consider data cleaning")
            if analysis['data_quality']['duplicates'] > 0:
                analysis['recommendations'].append(f"ğŸ”„ Found {analysis['data_quality']['duplicates']} duplicate rows")
            
            st.session_state.analyzed_data[filename] = analysis
            return analysis
            
        except Exception as e:
            return {'filename': uploaded_file.name, 'error': str(e)}
    
    def analyze_excel(self, uploaded_file):
        try:
            excel_data = pd.ExcelFile(uploaded_file)
            sheets_analysis = {}
            filename = uploaded_file.name
            
            for sheet_name in excel_data.sheet_names:
                df = pd.read_excel(uploaded_file, sheet_name=sheet_name)
                
                sheet_analysis = {
                    'sheet_name': sheet_name,
                    'rows': len(df),
                    'columns': len(df.columns),
                    'column_names': list(df.columns),
                    'dataframe': df,
                    'insurance_columns': [],
                    'summary_stats': {}
                }
                
                for col in df.columns:
                    col_lower = col.lower()
                    for category, keywords in self.insurance_keywords.items():
                        if any(keyword in col_lower for keyword in keywords):
                            sheet_analysis['insurance_columns'].append({
                                'column': col,
                                'category': category
                            })
                
                numeric_cols = df.select_dtypes(include=[np.number]).columns
                for col in numeric_cols:
                    if not df[col].empty and not df[col].isna().all():
                        sheet_analysis['summary_stats'][col] = {
                            'mean': float(df[col].mean()),
                            'sum': float(df[col].sum())
                        }
                
                sheets_analysis[sheet_name] = sheet_analysis
            
            analysis = {
                'filename': filename,
                'type': 'Excel',
                'sheets': sheets_analysis,
                'total_sheets': len(excel_data.sheet_names)
            }
            
            st.session_state.analyzed_data[filename] = analysis
            return analysis
            
        except Exception as e:
            return {'filename': uploaded_file.name, 'error': str(e)}
    
    def analyze_pdf(self, uploaded_file):
        try:
            filename = uploaded_file.name
            text_content = ""
            
            try:
                with pdfplumber.open(uploaded_file) as pdf:
                    for page in pdf.pages:
                        page_text = page.extract_text()
                        if page_text:
                            text_content += page_text + "\n"
            except:
                pdf_reader = PyPDF2.PdfReader(uploaded_file)
                for page in pdf_reader.pages:
                    text_content += page.extract_text() + "\n"
            
            analysis = {
                'filename': filename,
                'type': 'PDF',
                'text_content': text_content[:5000],
                'document_type': self._identify_document_type(text_content),
                'key_findings': self._extract_key_findings(text_content),
                'insurance_metrics': self._extract_insurance_metrics(text_content)
            }
            
            st.session_state.analyzed_data[filename] = analysis
            return analysis
            
        except Exception as e:
            return {'filename': uploaded_file.name, 'error': str(e)}
    
    def _identify_document_type(self, text):
        text_lower = text.lower()
        if any(word in text_lower for word in ['claim', 'loss run', 'incident']):
            return "Claims Document"
        elif any(word in text_lower for word in ['policy', 'certificate', 'coverage']):
            return "Policy Document"
        elif any(word in text_lower for word in ['financial', 'balance sheet', 'income']):
            return "Financial Document"
        else:
            return "General Document"
    
    def _extract_key_findings(self, text):
        findings = []
        
        money_pattern = r'\$[\d,]+\.?\d*'
        money_matches = re.findall(money_pattern, text)
        if money_matches:
            findings.append(f"Found {len(money_matches)} monetary amounts")
        
        date_pattern = r'\b\d{1,2}[/\-]\d{1,2}[/\-]\d{2,4}\b'
        date_matches = re.findall(date_pattern, text)
        if date_matches:
            findings.append(f"Found {len(date_matches)} date references")
        
        return findings
    
    def _extract_insurance_metrics(self, text):
        metrics = {}
        
        money_pattern = r'\$[\d,]+\.?\d*'
        money_amounts = re.findall(money_pattern, text)
        if money_amounts:
            metrics["monetary_amounts"] = len(money_amounts)
        
        limit_pattern = r'limit[s]?\s*[:\-]?\s*\$[\d,]+\.?\d*'
        limit_matches = re.findall(limit_pattern, text, re.IGNORECASE)
        if limit_matches:
            metrics["coverage_limits"] = len(limit_matches)
        
        return metrics
    
    def generate_chat_response(self, question):
        if not st.session_state.analyzed_data:
            return "ğŸ¤– Hi! I don't have any documents analyzed yet. Please upload and analyze some insurance files first, then I can answer questions about them!"
        
        question_lower = question.lower()
        response_parts = []
        
        if any(greeting in question_lower for greeting in ['hello', 'hi', 'hey']):
            files_count = len(st.session_state.analyzed_data)
            files_list = list(st.session_state.analyzed_data.keys())
            return f"ğŸ¤– Hello! I'm STEVE, your insurance analysis AI. I've analyzed {files_count} file(s): {', '.join(files_list)}. What would you like to know about your data?"
        
        if 'column' in question_lower or 'field' in question_lower:
            for filename, analysis in st.session_state.analyzed_data.items():
                if analysis['type'] in ['CSV', 'Excel']:
                    if analysis['type'] == 'CSV':
                        cols = analysis['column_names']
                        insurance_cols = [col['column'] for col in analysis['insurance_columns']]
                        response_parts.append(f"ğŸ“Š **{filename}** has {len(cols)} columns:")
                        response_parts.append(f"â€¢ All columns: {', '.join(cols)}")
                        if insurance_cols:
                            response_parts.append(f"â€¢ Insurance columns: {', '.join(insurance_cols)}")
                    elif analysis['type'] == 'Excel':
                        for sheet_name, sheet_info in analysis['sheets'].items():
                            cols = sheet_info['column_names']
                            response_parts.append(f"ğŸ“‹ **{filename} - {sheet_name}**: {', '.join(cols)}")
        
        elif any(word in question_lower for word in ['summary', 'overview', 'about']):
            for filename, analysis in st.session_state.analyzed_data.items():
                if analysis['type'] == 'CSV':
                    response_parts.append(f"ğŸ“„ **{filename}** Summary:")
                    response_parts.append(f"â€¢ {analysis['rows']:,} rows Ã— {analysis['columns']} columns")
                    response_parts.append(f"â€¢ Insurance columns detected: {len(analysis['insurance_columns'])}")
                elif analysis['type'] == 'PDF':
                    response_parts.append(f"ğŸ“„ **{filename}** Summary:")
                    response_parts.append(f"â€¢ Document Type: {analysis['document_type']}")
                    response_parts.append(f"â€¢ Key Findings: {', '.join(analysis['key_findings'])}")
        
        elif any(word in question_lower for word in ['total', 'sum', 'amount']):
            found_totals = False
            for filename, analysis in st.session_state.analyzed_data.items():
                if analysis['type'] == 'CSV' and analysis.get('summary_stats'):
                    response_parts.append(f"ğŸ’° **{filename}** - Financial Totals:")
                    for col, stats in analysis['summary_stats'].items():
                        if stats['sum'] > 0 and any(keyword in col.lower() for keyword in ['premium', 'amount', 'paid', 'loss', 'reserve']):
                            response_parts.append(f"â€¢ {col}: ${stats['sum']:,.2f} (avg: ${stats['mean']:,.2f})")
                            found_totals = True
            
            if not found_totals:
                response_parts.append("ğŸ” I couldn't find obvious monetary columns. Could you specify which amounts you're interested in?")
        
        elif any(word in question_lower for word in ['quality', 'missing', 'problem', 'issue']):
            for filename, analysis in st.session_state.analyzed_data.items():
                if analysis['type'] == 'CSV':
                    response_parts.append(f"âš ï¸ **{filename}** - Data Quality Report:")
                    
                    if analysis['data_quality']['missing_data']:
                        response_parts.append("â€¢ Missing data issues:")
                        for col, info in list(analysis['data_quality']['missing_data'].items())[:3]:
                            response_parts.append(f"  - {col}: {info['percentage']}% missing ({info['count']} rows)")
                    else:
                        response_parts.append("â€¢ âœ… No significant missing data")
                    
                    if analysis['data_quality']['duplicates'] > 0:
                        response_parts.append(f"â€¢ âš ï¸ {analysis['data_quality']['duplicates']} duplicate rows found")
                    else:
                        response_parts.append("â€¢ âœ… No duplicate rows")
        
        if not response_parts:
            available_files = ', '.join(st.session_state.analyzed_data.keys())
            response_parts.append(f"ğŸ¤” I'm not sure how to answer that. I have data from: {available_files}")
            response_parts.append("\nTry asking:")
            response_parts.append("â€¢ 'What columns do I have?'")
            response_parts.append("â€¢ 'Show me a summary'")
            response_parts.append("â€¢ 'What are the total amounts?'")
            response_parts.append("â€¢ 'Any data quality issues?'")
        
        return "\n".join(response_parts)

def main():
    steve = SteveWebApp()
    
    st.markdown('<div class="main-header">ğŸ¤– STEVE</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">Smart Technology for Evaluating insurance documents and Validating Exposures</div>', unsafe_allow_html=True)
    
    with st.sidebar:
        st.header("ğŸ“ Upload Documents")
        uploaded_files = st.file_uploader(
            "Choose insurance files to analyze",
            type=['csv', 'xlsx', 'xls', 'pdf'],
            accept_multiple_files=True,
            help="Upload CSV, Excel, or PDF files for analysis"
        )
        
        if uploaded_files:
            st.write(f"ğŸ“„ {len(uploaded_files)} file(s) uploaded")
            
            if st.button("ğŸš€ Analyze Files", type="primary"):
                with st.spinner("STEVE is analyzing your files..."):
                    for file in uploaded_files:
                        if file.name.endswith('.csv'):
                            result = steve.analyze_csv(file)
                        elif file.name.endswith(('.xlsx', '.xls')):
                            result = steve.analyze_excel(file)
                        elif file.name.endswith('.pdf'):
                            result = steve.analyze_pdf(file)
                        
                        if 'error' not in result:
                            st.success(f"âœ… Analyzed: {file.name}")
                        else:
                            st.error(f"âŒ Error with {file.name}: {result['error']}")
                
                st.rerun()
    
    if not st.session_state.analyzed_data:
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.markdown("""
            ### ğŸš€ Welcome to STEVE!
            
            Your AI-powered insurance document analysis platform specifically designed for P&C insurance companies.
            
            **What STEVE can analyze:**
            - ğŸ“Š Claims data and loss runs
            - ğŸ“‹ Policy information and coverage details
            - ğŸ’° Financial reports and premium data
            - ğŸ“„ Regulatory filings and compliance documents
            
            **Get started:**
            1. Upload your files using the sidebar
            2. Click "Analyze Files"
            3. Chat with STEVE about your data
            
            Ready to revolutionize your insurance data analysis? Upload your files to begin! ğŸš€
            """)
    
    else:
        tab1, tab2, tab3 = st.tabs(["ğŸ“Š Analysis Results", "ğŸ’¬ Chat with STEVE", "ğŸ“ˆ Visualizations"])
        
        with tab1:
            st.header("ğŸ“Š Analysis Results")
            
            for filename, analysis in st.session_state.analyzed_data.items():
                with st.expander(f"ğŸ“„ {filename}", expanded=True):
                    if 'error' in analysis:
                        st.error(f"Error: {analysis['error']}")
                        continue
                    
                    if analysis['type'] == 'CSV':
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Rows", f"{analysis['rows']:,}")
                        with col2:
                            st.metric("Columns", analysis['columns'])
                        with col3:
                            st.metric("Insurance Columns", len(analysis['insurance_columns']))
                        with col4:
                            quality_score = "Good" if not analysis['data_quality']['missing_data'] else "Issues"
                            st.metric("Data Quality", quality_score)
                        
                        if analysis['insurance_columns']:
                            st.subheader("ğŸ¢ Insurance Columns Detected")
                            for col_info in analysis['insurance_columns']:
                                st.write(f"â€¢ **{col_info['column']}** ({col_info['category']})")
                        
                        if analysis['data_quality']['missing_data']:
                            st.subheader("âš ï¸ Data Quality Issues")
                            for col, info in analysis['data_quality']['missing_data'].items():
                                st.warning(f"**{col}**: {info['percentage']}% missing data ({info['count']} rows)")
                    
                    elif analysis['type'] == 'Excel':
                        st.metric("Total Sheets", analysis['total_sheets'])
                        for sheet_name, sheet_info in analysis['sheets'].items():
                            st.write(f"ğŸ“‹ **{sheet_name}**: {sheet_info['rows']:,} rows Ã— {sheet_info['columns']} columns")
                    
                    elif analysis['type'] == 'PDF':
                        st.write(f"**Document Type**: {analysis['document_type']}")
                        if analysis['key_findings']:
                            st.write("**Key Findings**:")
                            for finding in analysis['key_findings']:
                                st.write(f"â€¢ {finding}")
        
        with tab2:
            st.header("ğŸ’¬ Chat with STEVE")
            
            if 'chat_history' not in st.session_state:
                st.session_state.chat_history = []
            
            for i, chat in enumerate(st.session_state.chat_history):
                with st.container():
                    st.markdown(f'<div class="user-message"><strong>You:</strong> {chat["user"]}</div>', unsafe_allow_html=True)
                    st.markdown(f'<div class="steve-response"><strong>ğŸ¤– STEVE:</strong> {chat["steve"]}</div>', unsafe_allow_html=True)
            
            user_question = st.text_input("Ask STEVE about your insurance data:", placeholder="What columns do I have?", key="chat_input")
            
            col1, col2 = st.columns([1, 4])
            with col1:
                if st.button("Send ğŸš€"):
                    if user_question:
                        response = steve.generate_chat_response(user_question)
                        st.session_state.chat_history.append({
                            "user": user_question,
                            "steve": response
                        })
                        st.rerun()
            
            with col2:
                if st.button("Clear Chat ğŸ—‘ï¸"):
                    st.session_state.chat_history = []
                    st.rerun()
            
            st.subheader("ğŸ’¡ Suggested Questions")
            suggested_questions = [
                "What columns do I have?",
                "Show me a summary of my data",
                "What are the total premium amounts?",
                "Are there any data quality issues?",
                "Tell me about claims data",
                "What do you recommend?"
            ]
            
            cols = st.columns(2)
            for i, question in enumerate(suggested_questions):
                with cols[i % 2]:
                    if st.button(question, key=f"suggest_{i}"):
                        response = steve.generate_chat_response(question)
                        st.session_state.chat_history.append({
                            "user": question,
                            "steve": response
                        })
                        st.rerun()
        
        with tab3:
            st.header("ğŸ“ˆ Data Visualizations")
            
            for filename, analysis in st.session_state.analyzed_data.items():
                if analysis['type'] == 'CSV' and analysis.get('summary_stats'):
                    st.subheader(f"ğŸ“Š {filename}")
                    
                    monetary_cols = []
                    for col, stats in analysis['summary_stats'].items():
                        if any(keyword in col.lower() for keyword in ['premium', 'amount', 'paid', 'loss', 'reserve']):
                            monetary_cols.append(col)
                    
                    if monetary_cols and len(monetary_cols) > 0:
                        df = analysis['dataframe']
                        
                        col = monetary_cols[0]
                        fig = px.histogram(df, x=col, title=f"Distribution of {col}")
                        st.plotly_chart(fig, use_container_width=True)
                        
                        stats_data = []
                        for col in monetary_cols:
                            if col in analysis['summary_stats']:
                                stats = analysis['summary_stats'][col]
                                stats_data.append({
                                    'Column': col,
                                    'Total': f"${stats['sum']:,.2f}",
                                    'Average': f"${stats['mean']:,.2f}",
                                    'Median': f"${stats['median']:,.2f}",
                                    'Min': f"${stats['min']:,.2f}",
                                    'Max': f"${stats['max']:,.2f}"
                                })
                        
                        if stats_data:
                            st.subheader("ğŸ“‹ Financial Summary")
                            st.dataframe(pd.DataFrame(stats_data), use_container_width=True)

if __name__ == "__main__":
    main()
